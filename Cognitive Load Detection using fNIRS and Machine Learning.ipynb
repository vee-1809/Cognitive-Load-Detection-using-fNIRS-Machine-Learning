{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d3754d2",
   "metadata": {},
   "source": [
    "# Cognitive Load Detection Using fNIRS & Machine Learning\n",
    "\n",
    "This notebook processes fNIRS brain signal data to detect a subjectâ€™s cognitive load level in real time and adapt educational content accordingly using both static templates and OpenAI GPT-4.\n",
    "\n",
    "**Key Features:**\n",
    "- Feature extraction from raw fNIRS chunks\n",
    "- Classification of cognitive load levels (low/medium/high)\n",
    "- Real-time simulation\n",
    "- Static and user-typed GPT prompt adaptation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a99d0f2",
   "metadata": {},
   "source": [
    "## # -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9893e469",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from ipywidgets import interact\n",
    "\n",
    "window_size = 300  # adjust based on actual sampling rate\n",
    "num_samples = df.shape[0]\n",
    "n_windows = num_samples // window_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d8b1d5",
   "metadata": {},
   "source": [
    "## Feature Extraction ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320d7921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    feature_row = {}\n",
    "    for col in df.columns:\n",
    "        if col != \"label\":\n",
    "            signal = df[col].values\n",
    "            feature_row[f\"{col}_mean\"] = np.mean(signal)\n",
    "            feature_row[f\"{col}_std\"] = np.std(signal)\n",
    "            feature_row[f\"{col}_slope\"] = np.polyfit(range(len(signal)), signal, 1)[0]\n",
    "            feature_row[f\"{col}_auc\"] = np.trapz(signal)\n",
    "    return feature_row\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_folder = \"/content/drive/MyDrive/FNIRS TUFTS/Band pass filtered\"\n",
    "all_files = glob.glob(os.path.join(data_folder, \"*.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55537c0",
   "metadata": {},
   "source": [
    "## Feature Extraction ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92957038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    feature_row = {}\n",
    "    for col in df.columns:\n",
    "        if col != \"label\":\n",
    "            signal = df[col].values\n",
    "            feature_row[f\"{col}_mean\"] = np.mean(signal)\n",
    "            feature_row[f\"{col}_std\"] = np.std(signal)\n",
    "            feature_row[f\"{col}_slope\"] = np.polyfit(range(len(signal)), signal, 1)[0]\n",
    "            feature_row[f\"{col}_auc\"] = np.trapz(signal)\n",
    "    return feature_row\n",
    "\n",
    "window_size = 300\n",
    "feature_list = []\n",
    "label_list = []\n",
    "\n",
    "for file in all_files:\n",
    "    df = pd.read_csv(file)\n",
    "    num_samples = df.shape[0]\n",
    "    n_windows = num_samples // window_size\n",
    "\n",
    "    for i in range(n_windows):\n",
    "        window_df = df.iloc[i*window_size : (i+1)*window_size]\n",
    "        if len(window_df) < window_size:\n",
    "            continue\n",
    "        features = extract_features(window_df)\n",
    "        label = int(window_df[\"label\"].iloc[0])\n",
    "        feature_list.append(features)\n",
    "        label_list.append(label)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pd.DataFrame(feature_list).select_dtypes(include=\"number\")\n",
    "y = pd.Series(label_list).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee662721",
   "metadata": {},
   "source": [
    "## Model Training ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbc5dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07bc567",
   "metadata": {},
   "source": [
    "## Visualization ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eda66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Cognitive Load - Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d376cac",
   "metadata": {},
   "source": [
    "## Visualization ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4426297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Cognitive Load - Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "# Plot top 10 features\n",
    "sorted_idx = importances.argsort()[::-1][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3863e80",
   "metadata": {},
   "source": [
    "## Visualization ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92c5b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x=importances[sorted_idx], y=features[sorted_idx])\n",
    "plt.title(\"ðŸ” Top 10 Feature Importances\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f797edb",
   "metadata": {},
   "source": [
    "## Model Training ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2631541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "scores = cross_val_score(clf, X, y, cv=skf)\n",
    "\n",
    "print(\"Cross-val accuracy (5-fold):\", scores.mean())\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "print(\"ðŸ“Š SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_svm), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"ðŸ§  SVM - Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "print(\"Gradient Boosting Report:\")\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_gb), annot=True, fmt=\"d\", cmap=\"Greens\")\n",
    "plt.title(\" Gradient Boosting - Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": clf,\n",
    "    \"SVM\": svm_model,\n",
    "    \"Gradient Boosting\": gb_model\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    print(f\"{name}: Accuracy = {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cd9b9a",
   "metadata": {},
   "source": [
    "## Prompt Generator ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43181ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(load_level, topic=\"Gravity\"):\n",
    "    if load_level == 3:  # High cognitive load â†’ simplify\n",
    "        return f\"Explain {topic} using simple language, short sentences, and bullet points. Avoid technical terms.\"\n",
    "    elif load_level == 2:\n",
    "        return f\"Explain {topic} with clear examples and simple vocabulary. Use paragraph form but keep it light.\"\n",
    "    elif load_level == 1:\n",
    "        return f\"Give a moderately detailed explanation of {topic} suitable for a middle school student.\"\n",
    "    else:  # load_level == 0 â†’ low load â†’ challenge them\n",
    "        return f\"Explain {topic} in a detailed way using high school-level vocabulary and relevant scientific terminology.\"\n",
    "\n",
    "# Assuming 'predicted_class' is the output from your classifier\n",
    "predicted_class = clf.predict(X_test)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f82a59b",
   "metadata": {},
   "source": [
    "## Prompt Generator ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a4c42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = generate_prompt(predicted_class, topic=\"Gravity\")\n",
    "print(\" Predicted Load:\", predicted_class)\n",
    "print(\" ChatGPT Prompt:\", prompt)\n",
    "\n",
    "\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key=\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2de260a",
   "metadata": {},
   "source": [
    "## GPT-4 API Call ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3576f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful science tutor.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"ðŸ’¬ ChatGPT Response:\\n\", response.choices[0].message.content)\n",
    "\n",
    "text_bank = {\n",
    "    \"gravity\": {\n",
    "        0: \"Gravity is a fundamental force of nature described by general relativity, responsible for the curvature of spacetime around massive objects.\",\n",
    "        1: \"Gravity is a natural force that pulls objects toward one another. It's what keeps the planets in orbit around the sun.\",\n",
    "        2: \"Gravity pulls things down, like how an apple falls from a tree.\",\n",
    "        3: \"Gravity makes things fall to the ground.\"\n",
    "    },\n",
    "    \"photosynthesis\": {\n",
    "        0: \"Photosynthesis is the biochemical process by which green plants, algae, and some bacteria convert light energy into chemical energy, producing glucose and oxygen from carbon dioxide and water.\",\n",
    "        1: \"Photosynthesis is how plants use sunlight to make their own food. They take in carbon dioxide and water to create oxygen and sugar.\",\n",
    "        2: \"Plants use sunlight to make food and give us oxygen.\",\n",
    "        3: \"Plants eat sunlight and help us breathe.\"\n",
    "    },\n",
    "    \"climate change\": {\n",
    "        0: \"Climate change refers to long-term alterations in temperature and weather patterns, primarily caused by anthropogenic greenhouse gas emissions affecting the Earthâ€™s energy balance.\",\n",
    "        1: \"Climate change is when Earth's weather becomes different over time, mainly due to human activities like burning fossil fuels.\",\n",
    "        2: \"The Earth is getting warmer because of pollution from cars and factories.\",\n",
    "        3: \"The Earth is getting hotter.\"\n",
    "    },\n",
    "    \"nervous system\": {\n",
    "        0: \"The nervous system comprises the central and peripheral systems, transmitting electrical and chemical signals between the brain, spinal cord, and body to regulate physiological processes.\",\n",
    "        1: \"The nervous system is how your brain and body communicate through nerves and signals.\",\n",
    "        2: \"Your brain sends messages to your body to move and feel things.\",\n",
    "        3: \"Your brain tells your body what to do.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "display_adapted_output(clf, X_test, \"nervous system\")\n",
    "\n",
    "text_bank = {\n",
    "    \"photosynthesis\": {...},\n",
    "    \"gravity\": {...},\n",
    "    \"climate change\": {...},\n",
    "    \"nervous system\": {...}\n",
    "}\n",
    "\n",
    "def display_adapted_output(model, X_sample, topic):\n",
    "    predicted_class = model.predict(X_sample)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9512c5cd",
   "metadata": {},
   "source": [
    "## Prompt Generator ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628123cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    prompt = generate_prompt(predicted_class, topic)\n",
    "    text = get_adapted_text(predicted_class, topic)\n",
    "\n",
    "    print(f\" Predicted Load Level: {predicted_class}\")\n",
    "    print(f\" ChatGPT Prompt:\\n{prompt}\")\n",
    "    print(f\"\\n Adapted Static Text:\\n{text}\")\n",
    "\n",
    "# Usage\n",
    "display_adapted_output(clf, X_test, \"gravity\")\n",
    "\n",
    "@interact(level=[0, 1, 2, 3], topic=[\"photosynthesis\", \"gravity\", \"climate change\",\"nervous system\"])\n",
    "def test_text(level, topic):\n",
    "    print(f\"Selected Topic: {topic}\")\n",
    "    print(f\"Load Level: {level}\")\n",
    "    print(\"Adapted Science Text:\\n\")\n",
    "    print(get_adapted_text(level, topic))\n",
    "\n",
    "#Level Generalization\n",
    "\n",
    "all_files = glob.glob(os.path.join(data_folder, \"*.csv\"))\n",
    "\n",
    "subject_data = {}  # key: subject ID or filename, value: dataframe\n",
    "\n",
    "for file in all_files:\n",
    "    subject_id = os.path.basename(file).split(\".\")[0]  # get filename without extension\n",
    "    df = pd.read_csv(file)\n",
    "    subject_data[subject_id] = df\n",
    "\n",
    "#Leave-One-Subject-Out Split\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "subjects = list(subject_data.keys())\n",
    "loo = LeaveOneOut()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff45c9ee",
   "metadata": {},
   "source": [
    "## Feature Extraction ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d8545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_labels(df, chunk_size=50):\n",
    "    import numpy as np\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(0, len(df), chunk_size):\n",
    "        chunk = df.iloc[i:i+chunk_size]\n",
    "        if len(chunk) < chunk_size:\n",
    "            continue  # skip incomplete chunks\n",
    "\n",
    "        # Drop non-signal columns if needed (like 'label')\n",
    "        signal_cols = [col for col in chunk.columns if col != \"label\"]\n",
    "\n",
    "        # Feature extraction: mean, std, min, max\n",
    "        feature_dict = {}\n",
    "        for col in signal_cols:\n",
    "            feature_dict[f\"{col}_mean\"] = chunk[col].mean()\n",
    "            feature_dict[f\"{col}_std\"] = chunk[col].std()\n",
    "            feature_dict[f\"{col}_min\"] = chunk[col].min()\n",
    "            feature_dict[f\"{col}_max\"] = chunk[col].max()\n",
    "\n",
    "        features.append(feature_dict)\n",
    "\n",
    "        # Label for this chunk: use majority or mode\n",
    "        labels.append(chunk[\"label\"].mode()[0])  # safest choice\n",
    "\n",
    "    return pd.DataFrame(features), labels\n",
    "\n",
    "#LOSO loop\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "results = []\n",
    "\n",
    "for train_idx, test_idx in loo.split(subjects):\n",
    "    train_subjects = [subjects[i] for i in train_idx]\n",
    "    test_subject = subjects[test_idx[0]]\n",
    "\n",
    "    # Combine train data\n",
    "    train_df = pd.concat([subject_data[s] for s in train_subjects])\n",
    "    test_df = subject_data[test_subject]\n",
    "\n",
    "    # Feature extraction (same as before)\n",
    "    X_train, y_train = extract_features_and_labels(train_df)\n",
    "    X_test, y_test = extract_features_and_labels(test_df)\n",
    "\n",
    "    # Train model\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"test_subject\": test_subject,\n",
    "        \"accuracy\": acc,\n",
    "        \"report\": classification_report(y_test, y_pred, output_dict=True)\n",
    "    })\n",
    "    print(f\"Tested on {test_subject} | Accuracy: {acc:.2f}\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Average Accuracy:\", results_df[\"accuracy\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc6affd",
   "metadata": {},
   "source": [
    "## Feature Extraction ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a0ef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_labels(df):\n",
    "    # Split df into time windows (e.g., 50 rows per chunk)\n",
    "    chunks = [df.iloc[i:i+50] for i in range(0, len(df), 50) if len(df.iloc[i:i+50]) == 50]\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        # Extract features from each chunk (mean, std, etc.)\n",
    "        f = extract_features(chunk)  # reuse your existing method\n",
    "        features.append(f)\n",
    "\n",
    "        # Get label from chunk (assuming 1 label per chunk)\n",
    "        labels.append(chunk[\"label\"].mode()[0])  # or majority vote\n",
    "\n",
    "    return pd.DataFrame(features), labels\n",
    "\n",
    "REAL TIME PIPELINE.\n",
    "\n",
    "import os, glob\n",
    "import pandas as pd\n",
    "\n",
    "data_folder = \"/content/drive/MyDrive/FNIRS TUFTS/Band pass filtered\"\n",
    "all_files = glob.glob(os.path.join(data_folder, \"*.csv\"))\n",
    "\n",
    "subject_data = {}\n",
    "for file in all_files:\n",
    "    subject_id = os.path.basename(file).split(\".\")[0]\n",
    "    df = pd.read_csv(file)\n",
    "    subject_data[subject_id] = df\n",
    "\n",
    "X_train, y_train = extract_features_and_labels(train_df)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c8bab2",
   "metadata": {},
   "source": [
    "## Model Training ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e52ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "import time\n",
    "\n",
    "chunk_size = 50  # based on your sampling rate\n",
    "test_chunks = [test_df.iloc[i:i+chunk_size] for i in range(0, len(test_df), chunk_size)]\n",
    "\n",
    "for chunk in test_chunks:\n",
    "    if len(chunk) < chunk_size:\n",
    "        continue\n",
    "\n",
    "    features = extract_features(chunk)\n",
    "    X = pd.DataFrame([features])\n",
    "    predicted_class = clf.predict(X)[0]\n",
    "\n",
    "    # Text adaptation\n",
    "    topic = \"gravity\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443fd6b7",
   "metadata": {},
   "source": [
    "## Prompt Generator ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b524baba",
   "metadata": {},
   "outputs": [],
   "source": [
    "    prompt = generate_prompt(predicted_class, topic)\n",
    "    static_text = get_adapted_text(predicted_class, topic)\n",
    "\n",
    "    print(f\" Predicted Load Level: {predicted_class}\")\n",
    "    print(f\" GPT Prompt: {prompt}\")\n",
    "    print(f\" Adapted Text:\\n{static_text}\")\n",
    "\n",
    "    time.sleep(0.1)  # simulate live delay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8a1045",
   "metadata": {},
   "source": [
    "## Feature Extraction ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68316ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_labels(df):\n",
    "    chunk_size = 50\n",
    "    chunks = [df.iloc[i:i+chunk_size] for i in range(0, len(df), chunk_size) if len(df.iloc[i:i+chunk_size]) == chunk_size]\n",
    "\n",
    "    features, labels = [], []\n",
    "    for chunk in chunks:\n",
    "        f = extract_features(chunk)\n",
    "        features.append(f)\n",
    "        labels.append(chunk[\"label\"].mode()[0])  # or majority vote\n",
    "\n",
    "    return pd.DataFrame(features), labels\n",
    "\n",
    "predictions = []\n",
    "timepoints = []\n",
    "true_labels = []  # optional, if your test data has labels\n",
    "\n",
    "for i, chunk in enumerate(test_chunks):\n",
    "    if len(chunk) < chunk_size:\n",
    "        continue\n",
    "\n",
    "    features = extract_features(chunk)\n",
    "    X = pd.DataFrame([features])\n",
    "    predicted_class = clf.predict(X)[0]\n",
    "\n",
    "    predictions.append(predicted_class)\n",
    "    timepoints.append(i)  # or use actual time if available\n",
    "\n",
    "    if \"label\" in chunk.columns:\n",
    "        true_labels.append(chunk[\"label\"].mode()[0])\n",
    "\n",
    "    # Your current adaptation block\n",
    "    ...\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6f9831",
   "metadata": {},
   "source": [
    "## Visualization ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d339e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfaba74",
   "metadata": {},
   "source": [
    "## Visualization ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef520246",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(timepoints, predictions, label=\"Predicted Load\", marker='o')\n",
    "\n",
    "# Optional: plot ground truth if available\n",
    "if true_labels:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7779189a",
   "metadata": {},
   "source": [
    "## Visualization ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72709cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "    plt.plot(timepoints, true_labels, label=\"True Load\", linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.xlabel(\"Time Window\")\n",
    "plt.ylabel(\"Cognitive Load Level\")\n",
    "plt.title(f\"ðŸ§  Cognitive Load Over Time â€“ {test_subject}\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
